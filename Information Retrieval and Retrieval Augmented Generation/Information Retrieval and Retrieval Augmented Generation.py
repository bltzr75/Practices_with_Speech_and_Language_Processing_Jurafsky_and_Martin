# -*- coding: utf-8 -*-
"""Chapter_13_Information Retrieval and Retrieval Augmented Generation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rMavG78XCUKvfpZe5ECJ4NAm1gRRrAaW

#Initial Setups
"""

!pip install -q pydantic evaluate transformers datasets accelerate bitsandbytes peft trl wandb
!pip install -q torch torchinfo sentence-transformers faiss-cpu chromadb whoosh
!pip install -q scikit-learn matplotlib seaborn pandas numpy
!pip install transformers

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import List, Dict, Tuple, Optional, Any, Union
import matplotlib.pyplot as plt
import seaborn as sns
from collections import defaultdict, Counter
import time
import math

# Pydantic for data validation
from pydantic import BaseModel, Field, field_validator, ConfigDict

# HuggingFace ecosystem
from transformers import (
    AutoTokenizer,
    AutoModel,
    AutoModelForCausalLM,
    BitsAndBytesConfig,
    TrainingArguments,
    Trainer
)
from datasets import Dataset as HFDataset
import evaluate  # HF evaluate library for metrics

# PEFT for parameter-efficient fine-tuning
from peft import LoraConfig, get_peft_model, TaskType, prepare_model_for_kbit_training

# TRL for RLHF and instruction tuning
from trl import SFTTrainer, DPOTrainer

# Accelerate for distributed training
from accelerate import Accelerator

# 8-bit optimization
import bitsandbytes as bnb

# IR libraries
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sentence_transformers import SentenceTransformer
import faiss  # Facebook AI Similarity Search for efficient nearest neighbor

# Experiment tracking
import wandb

# Set device and seeds
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
torch.manual_seed(42)
np.random.seed(42)
print(f"Using device: {device}")
if torch.cuda.is_available():
    print(f"GPU: {torch.cuda.get_device_name(0)}")
    print(f"Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")

"""#Data Structures and Pydantic Validation"""

class Document(BaseModel):
  """Document with validation using pydantic v2"""

  model_config = ConfigDict(
      extra='forbid',  # no extra fields allowed
      validate_assignment=True # validate on reassingment
  )


  doc_id: str = Field(..., min_length = 1, description="Document identifier")
  title: str = Field(..., min_length = 1, description="Document title")
  content: str = Field(..., min_length = 1, description="Document text content")
  metadata: Dict[str, Any] = Field(default_factory=dict, description="Additional metadata")

  @field_validator('content')
  @classmethod
  def validate_content(cls, v:str) -> str:
    """Ensure content is non-empty after stripping"""

    if not v.strip():
      raise ValueError("Content cannot be empty")
    return v.strip()


  def get_tokens(self) -> List[str]:
    """Simple whitespace tokenization"""

    return self.content.lower().split()


class Query(BaseModel):
  """Query with validation"""

  query_id: str = Field(..., min_length=1)
  text: str = Field(..., min_length=1)
  metadata: Dict[str, Any] = Field(default_factory=dict )

  def get_tokens(self) -> List[str]:
    """Tokenize query text"""

    return self.text.lower().split()


class DocumentCollection(BaseModel):
  """Collection of documents with indexing capabilities"""

  documents: List[Document] = Field(defualt_factory=list)

  def add_document(self, doc: Document):
    """Add validated document to collection"""

    self.documents.append(doc)


  def get_vocabulary(self) -> List[str]:
    """Extract unique vocabulary from all the documents"""

    vocab = set()
    for doc in self.documents:
      vocab.update(doc.get_tokens()) # Adding all the tokens to the set

    return sorted(list(vocab))

"""##Simple test with Shakespeare corpus from the book"""

shakespeare_docs = [
  Document(
    doc_id="as_you_like_it",
    title="As You Like It",
    content="battle good fool wit love forest magic",
    metadata={"genre": "comedy", "year": 1599}
  ),
  Document(
    doc_id="twelfth_night",
    title="Twelfth Night",
    content="good fool wit love comedy mistaken identity",
    metadata={"genre": "comedy", "year": 1602}
  ),
  Document(
    doc_id="julius_caesar",
    title="Julius Caesar",
    content="battle battle battle good fool war rome politics",
    metadata={"genre": "tragedy", "year": 1599}
  ),
  Document(
    doc_id="henry_v",
    title="Henry V",
    content="battle battle battle battle good wit war king england",
    metadata={"genre": "history", "year": 1599}
  )
]

collection = DocumentCollection(documents=shakespeare_docs)
print(f"Created collection with {len(collection.documents)} documents")
print(f"Vocabulary size: {len(collection.get_vocabulary())} unique terms")
print(f"Sample vocabulary: {collection.get_vocabulary()[:5]}")

"""# TF-IDF with scikit-learn"""

class TFIDFRetriever:
  """TF-idf retriever with pydantic validation and sklearn"""

  def __init__(self, collection: DocumentCollection):
    self.collection = collection
    self.vectorizer = TfidfVectorizer(
      lowercase=True,  #convert to lowercase
      max_features=1000, # max vocab size
      ngram_range=(1,2), # use unigrams and bigrams
      sublinear_tf=True, # log(tf) instead of just raw tf
      smooth_idf=True, # Laplace smoothing
      norm='l2' # normalize with ridge for cos sim
    )

    self.tfidf_matrix = None
    self.doc_ids = []


  def fit(self):
    """Build TF-IDF matrix from doc collection"""

    texts = []

    for doc in self.collection.documents:
      texts.append(doc.content)
      self.doc_ids.append(doc.doc_id) # storing doc ids


    print("Documents from test")
    print("Row 0: battle good fool wit love forest magic")
    print("Row 1: good fool wit love comedy mistaken identity")
    print("Row 2: battle battle battle good fool war rome politics")
    print("Row 3: battle battle battle battle good wit war king england")


    # fit and transform docs to tf idf matrix
    self.tfidf_matrix = self.vectorizer.fit_transform(texts) # [n_docs, n_features]  n_docs x vocab per doc
    print(f"\nself.tfidf_matrix.shape: {self.tfidf_matrix.shape}\n")
    print(f"\nself.tfidf_matrix:\n {self.tfidf_matrix}\n")


  def search(self,query: Query, top_k: int=3) -> List[Tuple[Document,float]]:
    """Search doc using tf-idf cos similarity"""

    # Transform qry to tf-idf vector
    query_vector = self.vectorizer.transform([query.text]) # [1, n_features]  single vector with all the features/words

    # Compute cos similarity
    similarities = cosine_similarity(query_vector, self.tfidf_matrix).flatten()

    print(f"\nQuery: '{query.text}'")
    print(f"Query vector shape: {query_vector.shape}")
    print(f"Similarities: {similarities}")

    # Top-k doc indices
    top_indices = np.argsort(similarities)[-top_k:][::-1] # sort desc

    results = []

    for idx in top_indices:
      doc = self.collection.documents[idx]
      score = similarities[idx]
      results.append((doc, score))
      print(f"  Rank {len(results)}: '{doc.title}' (score={score:.4f})")

    return results

"""# Simple test for the TF-IDF Retriever"""

retriever = TFIDFRetriever(collection)
retriever.fit()


# Get the feature names (what each column represents)
print("\nUnigrams and bigrams:\n")
feature_names = retriever.vectorizer.get_feature_names_out()
for idx, feature in enumerate(feature_names):
    print(f"Column {idx}: '{feature}'")

test_query = Query(query_id="q1", text="battle war")
results = retriever.search(test_query, top_k=3)

"""### Display TF-IDF matrix"""

# make df
tfidf_df = pd.DataFrame(
  retriever.tfidf_matrix.toarray(),
  columns=feature_names,
  index=[f"Doc{i}" for i in range(len(shakespeare_docs))]
)
tfidf_df

"""# BM25 Scorer"""

class BM25Scorer:
  """BM25 scoring with parameter tuning"""

  def __init__(self, collection: DocumentCollection, k1: float=1.2, b:float=0.75):
    """
    k1: controls term frequency saturation (typically 1.2-2.0). Enough to give score to a repeated word but not making a word repeated 100 times 100 times more important.
    b: controls length normalization (0=no normalization, 1=full normalization). Regularization over too large docs.
    """

    self.collection = collection
    self.k1 = k1 # Term frequency saturation param
    self.b = b   # Length normalization param
    self.doc_lengths = {} # Store doc lengths
    self.avg_doc_length = 0 # Avg doc length
    self.doc_freqs = defaultdict(int) # doc freqs per term
    self.N = len(collection.documents) # total num of docs
    self.term_freqs = {} # Term freqs per doc

    self._compute_statistics()


  def _compute_statistics(self):
    """Copmute doc statistics for BM25"""

    total_length = 0

    for doc in self.collection.documents:
      tokens = doc.get_tokens()
      doc_length = len(tokens)
      self.doc_lengths[doc.doc_id] = doc_length
      total_length += doc_length

      # Count term freq for this doc
      term_freq = defaultdict(int)
      unique_terms = set()
      for token in tokens:
        term_freq[token] += 1 # add 1 on occurence
        unique_terms.add(token)

      self.term_freqs[doc.doc_id] = term_freq

      # Update doc frequencies
      for term in unique_terms:
        self.doc_freqs[term] += 1 # Increment doc freq per term


    # Compute avg length
    self.avg_doc_length = total_length / self.N


    print(f"BM25 Statistics:")
    print(f"  Documents: {self.N}")
    print(f"  Avg doc length: {self.avg_doc_length:.2f}")
    print(f"  Unique terms: {len(self.doc_freqs)}")


  def score(self, query: Query, doc: Document) -> float:
    """
    Compute BM25 score for query-document pair.

    BM25(q,d) = Σ IDF(t) * (tf(t,d) * (k1 + 1)) / (tf(t,d) + k1 * (1 - b + b * |d|/avgdl))

    Where for each term t in query q:
      - IDF(t) = log((N - df(t) + 0.5) / (df(t) + 0.5)) — inverse document frequency
      - tf(t,d) = frequency of term t in document d
      - |d| = length of document d (number of terms)
      - avgdl = average document length in collection
      - k1 = term frequency saturation parameter (default 1.2). Keeps repeated more important but not in a linear scale per occureance.
      - b = length normalization parameter (0=none, 1=full, default 0.75). Penalizes too long docs.

    The formula balances term importance (IDF) with normalized term frequency,
    preventing bias toward longer documents while rewarding term repetition up to a limit.
    """

    score = 0.0
    query_terms = query.get_tokens() # query terms
    doc_length = self.doc_lengths[doc.doc_id]

    for term in query_terms:
      if term not in self.doc_freqs:
        continue # skip terms not in the collection


      # Compute IDF: log((N-df + 0.5)/ (df + 0.5) )

      df = self.doc_freqs[term] # Doc freq

      idf = math.log((self.N - df + 0.5) / (df + 0.5)) # Inv Doc Freq with smoothing
      print("\n\n\nidf = math.log((self.N - df + 0.5) / (df + 0.5))\n")
      print(f"{idf:.3f} = math.log(({self.N} - {df} + 0.5) / ({df} + 0.5))\n")


      # Get term freq in doc
      tf = self.term_freqs[doc.doc_id].get(term, 0)
      print(f"tf = {tf}\n\n")

      #Compute normalized term freq
      # tf_normalized (tf * (k1 + 1)) / (tf + k1 * (1 - b + b * |d| / avgdl ))

      norm_factor = 1 - self.b + self.b * (doc_length / self.avg_doc_length)
      tf_component = (tf * (self.k1 + 1 )) / (tf + self.k1 * norm_factor) # Normalized TF


      # Add to score
      term_score = idf * tf_component # idf * normalized tf
      score += term_score

      if tf > 0:  # Only print for terms that appear in document
        print(f"    Term '{term}': tf={tf}, df={df}, idf={idf:.3f}, contribution={term_score:.3f}")
        print("\n", "-"*50,"\n")

    return score


  def search(self, query: Query, top_k: int = 3) -> List[Tuple[Document, float]]:
    """Search documents using BM25 scoring"""

    scores = []

    print(f"\nBM25 Search for: '{query.text}'")

    for doc in self.collection.documents:
      score = self.score(query, doc) # compute bm25 score
      scores.append((doc, score))
      print(f"  '{doc.title}': {score:.4f}")

    # Sort desc by score
    scores.sort(key=lambda x: x[1], reverse=True)

    # Return top k
    return scores[:top_k]

# Test BM25 scorer
bm25 = BM25Scorer(collection, k1=1.2, b=0.75)
query = Query(query_id="q2", text="battle fool")
bm25_results = bm25.search(query, top_k=3)



print("\n\n")
print("\nThe negative IDF -0.847 here means these terms are so common they're actually penalizing the scores rather than helping.")

print("\nHigh IDF = term is RARE, appears in few documents -> very distinctive/important")
print("\nLow/Negative IDF = term is COMMON, appears in many documents -> not distinctive\n")


print("\nTop BM25 Results:")
for rank, (doc, score) in enumerate(bm25_results, 1):
    print(f"  {rank}. {doc.title}: {score:.4f}")

