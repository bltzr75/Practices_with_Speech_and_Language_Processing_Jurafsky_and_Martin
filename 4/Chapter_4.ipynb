{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Import libs and downloads\n",
        "\n"
      ],
      "metadata": {
        "id": "nXDr8edrYPfL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "L_5Ye8_W9wfB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer # Text to num feature conversion\n",
        "from sklearn.naive_bayes import MultinomialNB # Standard multinomial naive Bayes described in the chapter - uses word counts/frequencies as features\n",
        "from sklearn.naive_bayes import BernoulliNB #  \"Multivariate Bernoulli naive Bayes\" (different from binary multinomial NB) - estimates P(w|c) as the fraction of documents containing a term and includes probability for term absence\n",
        "from sklearn.model_selection import train_test_split, cross_val_score # Data splitting and validation\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "import nltk # nat lang tool kit\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import re\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download required NLTK data (one-time setup)\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fgot1or8VDHI",
        "outputId": "cb4fd797-04c5-4aa1-b634-dc987b8c8bb8"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text sample with ground truth/gold labels"
      ],
      "metadata": {
        "id": "Qs3mFXy_YZx3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Each text represents a document to classify\n",
        "texts = [\n",
        "    \"I love this movie!.... It's sweet, but with satirical humor.\",  # Positive sentiment\n",
        "    \"The dialogue is great and the adventure scenes are fun.\",   # Positive sentiment\n",
        "    \"It was pathetic. The worst part about it was the boxing scenes.\",  # Negative sentiment\n",
        "    \"No plot twists or great scenes. Entirely predictable.\",     # Negative sentiment\n",
        "    \"Awesome caramel sauce and sweet toasty almonds. I love this place!\",  # Positive sentiment\n",
        "    \"Awful pizza and ridiculously overpriced food.\",            # Negative sentiment\n",
        "    \"Very powerful and the most fun film of the summer.\",       # Positive sentiment\n",
        "    \"Just plain boring and lacks energy. No surprises.\"         # Negative sentiment\n",
        "]\n",
        "\n",
        "# Corresponding labels for each text (ground truth)\n",
        "labels = ['positive', 'positive', 'negative', 'negative',\n",
        "          'positive', 'negative', 'positive', 'negative']\n"
      ],
      "metadata": {
        "id": "Ucf1CkPqURWz"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic preprocessing"
      ],
      "metadata": {
        "id": "EmIkZl-xYfMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic preprocessing like the one from the book\n",
        "def preprocess_text(text):\n",
        "  \"\"\"Clean and normalize text for processing\"\"\"\n",
        "\n",
        "  text = text.lower()\n",
        "  # Removing punctuation but keeping spaces and letters/numbers\n",
        "  text = re.sub(r'[^\\w\\s]','',text) ## caret = the opposite(in this case: non words, non spaces); \\w = words ; \\s = whitespaces\n",
        "  return text\n",
        "\n",
        "processed_texts = [preprocess_text(text) for text in texts]\n",
        "print(\"Processed texts: \" )\n",
        "print(processed_texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPXRPrpdVoll",
        "outputId": "d4d72a12-b096-41df-8fff-df324c52d519"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed texts: \n",
            "['i love this movie its sweet but with satirical humor', 'the dialogue is great and the adventure scenes are fun', 'it was pathetic the worst part about it was the boxing scenes', 'no plot twists or great scenes entirely predictable', 'awesome caramel sauce and sweet toasty almonds i love this place', 'awful pizza and ridiculously overpriced food', 'very powerful and the most fun film of the summer', 'just plain boring and lacks energy no surprises']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Naive Bayes Algorithm"
      ],
      "metadata": {
        "id": "XgOEZG6JXRAY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict, Counter\n",
        "import math # for log operations"
      ],
      "metadata": {
        "id": "PAChO576Wkkv"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NaiveBayesClassifier:\n",
        "  def __init__(self, smoothing=1):\n",
        "    self.smoothing = smoothing # default as laplace add-one\n",
        "    self.class_priors = {} # P(c) Prob of classes\n",
        "    self.word_likelihoods = defaultdict(dict) # P(w|c) Prob of the word given the class\n",
        "    self.vocabulary = set() # Cardinality/size of the vocabulary. Unique words\n",
        "\n",
        "  def train(self, texts, labels):\n",
        "    \"\"\" Train the Naive Bayes classifier\"\"\"\n",
        "\n",
        "    class_counts = Counter(labels) ## for the Prior probability. Would be: Counter({'positive': 4, 'negative': 4})\n",
        "    total_docs = len(labels)\n",
        "\n",
        "    # Calc Prior probability count(class)/total docs\n",
        "    for class_label, count in class_counts.items(): # dict_items([('positive', 4), ('negative', 4)])\n",
        "      self.class_priors[class_label] = count/total_docs # MLE for the probs of the classes or labels, using just the frequency\n",
        "      print(\"self.class_priors: \", str(self.class_priors))\n",
        "\n",
        "    class_word_counts = defaultdict(Counter) # Counts each word in each class\n",
        "    class_total_words = defaultdict(int) # Total words in each class\n",
        "\n",
        "    for text, label in zip(texts, labels):\n",
        "      words = text.split() # Tokenizing by split on whitespaces\n",
        "      for word in words:\n",
        "        self.vocabulary.add(word)\n",
        "        class_word_counts[label][word] +=1\n",
        "        class_total_words[label] += 1\n",
        "\n",
        "    # Calculate the word likelihoods P(w|c) using add-one (laplace) smoothing\n",
        "    vocab_size = len(self.vocabulary) # |V|\n",
        "    for class_label in class_counts:\n",
        "      for word in self.vocabulary:\n",
        "        count = class_word_counts[class_label][word] # Raw count of word in class\n",
        "        # (count + 1) / (total_words + |V|): it is the frequency of the word in the specific class, with an adding of smoothing to not have zeros\n",
        "        self.word_likelihoods[class_label][word] = (\n",
        "            (count + self.smoothing) /\n",
        "            (class_total_words[class_label] + vocab_size * self.smoothing)\n",
        "        )\n",
        "\n",
        "\n",
        "  def predict(self, text):\n",
        "    \"\"\"Predict the class for a given text using Naive Bayes\"\"\"\n",
        "\n",
        "    words = text.split()\n",
        "    class_scores = {} # For storing log probabilities per class, logs avoid underflow and other benefits\n",
        "\n",
        "    ## It will go summing up the logs of the probabilities instead of the raw probabilities\n",
        "    for class_label in self.class_priors:\n",
        "      score = math.log(self.class_priors[class_label]) # log P(c)\n",
        "\n",
        "      # Adding log likelihood for each word in the doc\n",
        "      for word in words:\n",
        "        if word in self.vocabulary: # Only known words, if not will be a problematic 0\n",
        "          score += math.log(self.word_likelihoods[class_label][word])\n",
        "\n",
        "      class_scores[class_label] = score # stores final score for the class\n",
        "\n",
        "    print(\"class_scores: \", str(class_scores))\n",
        "    print(\"class probs: \")\n",
        "    print({class_label: math.exp(log_prob) for class_label, log_prob in class_scores.items()} )\n",
        "\n",
        "    # Predicts/retrieves the class with the max probability scored from the class_scores. Argmax function\n",
        "    return max(class_scores, key=class_scores.get)\n",
        "\n"
      ],
      "metadata": {
        "id": "2q6uZ3aMXbiw"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_classifier = NaiveBayesClassifier()\n",
        "nb_classifier.train(processed_texts, labels)\n"
      ],
      "metadata": {
        "id": "JsN4oQp_kbI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_text = \"This movie... is... great and fun!\"\n",
        "prediction = nb_classifier.predict(preprocess_text(test_text))\n",
        "print(f\"\\nPrediction for '{test_text}': {prediction}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSYgeLwrZh8t",
        "outputId": "0cdfbfd0-88f9-47a8-b409-5e7f32769adf"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class_scores:  {'positive': -22.416275849231017, 'negative': -25.833205929724727}\n",
            "class probs: \n",
            "{'positive': 1.839649530104649e-10, 'negative': 6.036444539388965e-12}\n",
            "\n",
            "Prediction for 'This movie... is... great and fun!': positive\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_text_2 = \"It was boring.\"\n",
        "prediction_2 = nb_classifier.predict(preprocess_text(test_text_2))\n",
        "print(f\"\\nPrediction for '{test_text_2}': {prediction_2}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXaoEDG9kZ9r",
        "outputId": "06937bad-9785-422e-fa24-0aeb5cedd702"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class_scores:  {'positive': -14.386191754963454, 'negative': -11.268684531860199}\n",
            "class probs: \n",
            "{'positive': 5.651403356481483e-07, 'negative': 1.2766518811465485e-05}\n",
            "\n",
            "Prediction for 'It was boring.': negative\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handling Negation\n"
      ],
      "metadata": {
        "id": "BWLRTCWGeKEM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def handle_negation(text):\n",
        "  \"\"\"\n",
        "  Implementation of negation handling as described in the book, section 4.4\n",
        "  Add NOT_ prefix to words after negation until punctuation\n",
        "  \"\"\"\n",
        "\n",
        "  # Words that indicate negation (from chapter examples)\n",
        "  negation_words = ['not', 'no', 'never', 'nothing', 'nowhere', 'nobody',\n",
        "                    'none', 'neither', 'nor', 'dont', \"don't\", 'didnt',\n",
        "                    \"didn't\", 'wont', \"won't\", 'cant', \"can't\"]\n",
        "\n",
        "  words = text.split() # Simple tonekizer for individual words\n",
        "  result = []\n",
        "  negated = False # Flag that sets scope of negation, starts with detected word and closes with punctuation\n",
        "\n",
        "\n",
        "  for word in words:\n",
        "    clean_word = re.sub('[^\\w]', '', word.lower()) # Cleaned to detect negation from the negation_words: lowercase and remove non-word chars\n",
        "\n",
        "    if clean_word in negation_words: ## Detected negation words\n",
        "      print(\"Detected negation: \", word)\n",
        "      negated = True # Changing flag\n",
        "      result.append(word) ## Adding the original negation word as it is\n",
        "\n",
        "    elif any(char in word for char in '.:,;!?'): ## Detected punctuation: Punctuation chars close the negated flag scope\n",
        "      print(\"Detected punctuation: \", word)\n",
        "      result.append(f\"NOT_{word}\" if negated else word)\n",
        "      negated = False # Changing flag\n",
        "\n",
        "\n",
        "    else: ## Detected common word: applying the _NOT prefic only if the negated flag is true\n",
        "      result.append(f\"NOT_{word}\" if negated else word)\n",
        "\n",
        "  return(' '.join(result))\n",
        "\n"
      ],
      "metadata": {
        "id": "cNxgbjmjg2on"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example from the chapter\n",
        "text = \"didn't like this movie , but I\"\n",
        "negated_text = handle_negation(text)\n",
        "print(f\"Original: {text}\")\n",
        "print(f\"Negated:  {negated_text}\")  # Should show: didn't NOT_like NOT_this NOT_movie , but I"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pxs6o_Pqk8C",
        "outputId": "cb82c43f-fc92-4465-ee22-a283881ebced"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected negation:  didn't\n",
            "Detected punctuation:  ,\n",
            "Original: didn't like this movie , but I\n",
            "Negated:  didn't NOT_like NOT_this NOT_movie NOT_, but I\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Binary vs. Multinomial Naive Bayes"
      ],
      "metadata": {
        "id": "GXkWDmYCvONp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    processed_texts, labels, # Documents and their gold labels\n",
        "    test_size= 0.3,  # Splits by docs, not by words: 5 docs go to train, and 3 to test\n",
        "    random_state = 42\n",
        "    )\n"
      ],
      "metadata": {
        "id": "aHkJjz3-te9R"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multinomial Naive Bayes (uses actual word counts)\n"
      ],
      "metadata": {
        "id": "SRTI_xj-1Fsa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Multinomial NB\n",
        "count_vectorizer = CountVectorizer() #  implements the bag of words by ignoring word order, counting frequencies, building a vocabulary, and converting texts to numerical vectors where each dimension represents word counts\n",
        "X_train_counts = count_vectorizer.fit_transform(X_train) # Creates sparse matrix for train data.  ## Example: \"(0, 13) 1 means Document 0, word at vocabulary index 13, appears 1 time\n",
        "X_test_counts  = count_vectorizer.transform(X_test) # Creates sparse matrix for test data\n",
        "\n"
      ],
      "metadata": {
        "id": "NLa9pumx1Ees"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## sparse matrix\n",
        "print(\"X_train_counts:\", str(X_train_counts))  ## Example: \"(0, 13) 1 means Document 0, word at vocabulary index 13, appears 1 time\n",
        "print(\"X_test_counts:\", str(X_test_counts))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "zP3BLcfUvl1R",
        "outputId": "e70030de-f014-4857-8ea9-277c4b762281"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_counts: <Compressed Sparse Row sparse matrix of dtype 'int64'\n",
            "\twith 44 stored elements and shape (5, 39)>\n",
            "  Coords\tValues\n",
            "  (0, 13)\t1\n",
            "  (0, 23)\t1\n",
            "  (0, 4)\t1\n",
            "  (0, 2)\t1\n",
            "  (0, 14)\t1\n",
            "  (0, 7)\t1\n",
            "  (0, 17)\t1\n",
            "  (0, 30)\t1\n",
            "  (1, 12)\t2\n",
            "  (1, 37)\t2\n",
            "  (1, 21)\t1\n",
            "  (1, 32)\t2\n",
            "  (1, 38)\t1\n",
            "  (1, 20)\t1\n",
            "  (1, 0)\t1\n",
            "  (1, 5)\t1\n",
            "  (1, 28)\t1\n",
            "  (2, 2)\t1\n",
            "  (2, 3)\t1\n",
            "  (2, 6)\t1\n",
            "  (2, 27)\t1\n",
            "  (2, 31)\t1\n",
            "  (2, 34)\t1\n",
            "  (2, 1)\t1\n",
            "  (2, 15)\t1\n",
            "  (2, 33)\t1\n",
            "  (2, 22)\t1\n",
            "  (3, 17)\t1\n",
            "  (3, 28)\t1\n",
            "  (3, 24)\t1\n",
            "  (3, 35)\t1\n",
            "  (3, 19)\t1\n",
            "  (3, 11)\t1\n",
            "  (3, 8)\t1\n",
            "  (3, 26)\t1\n",
            "  (4, 2)\t1\n",
            "  (4, 32)\t2\n",
            "  (4, 36)\t1\n",
            "  (4, 25)\t1\n",
            "  (4, 16)\t1\n",
            "  (4, 10)\t1\n",
            "  (4, 9)\t1\n",
            "  (4, 18)\t1\n",
            "  (4, 29)\t1\n",
            "X_test_counts: <Compressed Sparse Row sparse matrix of dtype 'int64'\n",
            "\twith 9 stored elements and shape (3, 39)>\n",
            "  Coords\tValues\n",
            "  (0, 2)\t1\n",
            "  (0, 10)\t1\n",
            "  (0, 11)\t1\n",
            "  (0, 28)\t1\n",
            "  (0, 32)\t2\n",
            "  (1, 2)\t1\n",
            "  (2, 15)\t1\n",
            "  (2, 31)\t1\n",
            "  (2, 33)\t1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "multinomial_nb = MultinomialNB(alpha=1.0) # Smoothing of 1.0\n",
        "multinomial_nb.fit(X_train_counts, y_train)\n",
        "\n",
        "print(\"multinomial_nb trained:\\n\")\n",
        "\n",
        "# Show the key attributes of the trained model\n",
        "print(\"Classes:\", multinomial_nb.classes_)  # Class labels ['negative', 'positive']\n",
        "\n",
        "print(\"\\nClass log priors:\", multinomial_nb.class_log_prior_)  # log P(c) for each class\n",
        "print(\"Class priors (actual):\", np.exp(multinomial_nb.class_log_prior_))  # P(c)\n",
        "\n",
        "print(\"\\nVocabulary size:\", len(count_vectorizer.vocabulary_))  # Number of unique words\n",
        "print(\"Feature names (first 10):\", count_vectorizer.get_feature_names_out()[:10])  # First 10 words\n",
        "\n",
        "print(\"\\nFeature log probabilities shape:\", multinomial_nb.feature_log_prob_.shape)  # (classes, features)\n",
        "# This is log P(word|class) for each word in each class\n",
        "\n",
        "# Example: probability of first few words given each class\n",
        "for i, class_name in enumerate(multinomial_nb.classes_):\n",
        "    print(f\"\\n{class_name} class - first word in probability:\")\n",
        "    for j in range(1):\n",
        "        word = count_vectorizer.get_feature_names_out()[j]\n",
        "        log_prob = multinomial_nb.feature_log_prob_[i][j]\n",
        "        actual_prob = np.exp(log_prob)\n",
        "        print(f\"  P('{word}'|{class_name}) = {actual_prob:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-MII7LRwsWe",
        "outputId": "0c75934c-2560-4374-995f-20f35f6cf849"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "multinomial_nb trained:\n",
            "\n",
            "Classes: ['negative' 'positive']\n",
            "\n",
            "Class log priors: [-0.51082562 -0.91629073]\n",
            "Class priors (actual): [0.6 0.4]\n",
            "\n",
            "Vocabulary size: 39\n",
            "Feature names (first 10): ['about' 'almonds' 'and' 'awesome' 'boring' 'boxing' 'caramel' 'energy'\n",
            " 'entirely' 'film']\n",
            "\n",
            "Feature log probabilities shape: (2, 39)\n",
            "\n",
            "negative class - first word in probability:\n",
            "  P('about'|negative) = 0.029851\n",
            "\n",
            "positive class - first word in probability:\n",
            "  P('about'|positive) = 0.016949\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Binary Naive Bayes (uses only presence/absence of words)\n"
      ],
      "metadata": {
        "id": "8vWn9eTt1KrS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binary_vectorizer = CountVectorizer(binary=True) # binary=True converts counts to just 0 or 1\n",
        "X_train_binary = binary_vectorizer.fit_transform(X_train)\n",
        "X_test_binary = binary_vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "PezBOL_NzXc4"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X_train_binary:\", str(X_train_binary))\n",
        "print(\"X_test_binary:\", str(X_test_binary))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FwAoD0vb1jBt",
        "outputId": "0cf20a12-87b5-44b2-8e0d-6005fefe1dc5"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_binary: <Compressed Sparse Row sparse matrix of dtype 'int64'\n",
            "\twith 44 stored elements and shape (5, 39)>\n",
            "  Coords\tValues\n",
            "  (0, 13)\t1\n",
            "  (0, 23)\t1\n",
            "  (0, 4)\t1\n",
            "  (0, 2)\t1\n",
            "  (0, 14)\t1\n",
            "  (0, 7)\t1\n",
            "  (0, 17)\t1\n",
            "  (0, 30)\t1\n",
            "  (1, 12)\t1\n",
            "  (1, 37)\t1\n",
            "  (1, 21)\t1\n",
            "  (1, 32)\t1\n",
            "  (1, 38)\t1\n",
            "  (1, 20)\t1\n",
            "  (1, 0)\t1\n",
            "  (1, 5)\t1\n",
            "  (1, 28)\t1\n",
            "  (2, 2)\t1\n",
            "  (2, 3)\t1\n",
            "  (2, 6)\t1\n",
            "  (2, 27)\t1\n",
            "  (2, 31)\t1\n",
            "  (2, 34)\t1\n",
            "  (2, 1)\t1\n",
            "  (2, 15)\t1\n",
            "  (2, 33)\t1\n",
            "  (2, 22)\t1\n",
            "  (3, 17)\t1\n",
            "  (3, 28)\t1\n",
            "  (3, 24)\t1\n",
            "  (3, 35)\t1\n",
            "  (3, 19)\t1\n",
            "  (3, 11)\t1\n",
            "  (3, 8)\t1\n",
            "  (3, 26)\t1\n",
            "  (4, 2)\t1\n",
            "  (4, 32)\t1\n",
            "  (4, 36)\t1\n",
            "  (4, 25)\t1\n",
            "  (4, 16)\t1\n",
            "  (4, 10)\t1\n",
            "  (4, 9)\t1\n",
            "  (4, 18)\t1\n",
            "  (4, 29)\t1\n",
            "X_test_binary: <Compressed Sparse Row sparse matrix of dtype 'int64'\n",
            "\twith 9 stored elements and shape (3, 39)>\n",
            "  Coords\tValues\n",
            "  (0, 2)\t1\n",
            "  (0, 10)\t1\n",
            "  (0, 11)\t1\n",
            "  (0, 28)\t1\n",
            "  (0, 32)\t1\n",
            "  (1, 2)\t1\n",
            "  (2, 15)\t1\n",
            "  (2, 31)\t1\n",
            "  (2, 33)\t1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "binary_nb = BernoulliNB(alpha=1.0) # Binary variant of NB\n",
        "binary_nb.fit(X_train_binary, y_train)\n",
        "\n",
        "\n",
        "print(\"binary_nb trained:\\n\")\n",
        "\n",
        "# Show the key attributes of the trained BernoulliNB model\n",
        "print(\"Classes:\", binary_nb.classes_)  # Class labels ['negative', 'positive']\n",
        "\n",
        "print(\"\\nClass log priors:\", binary_nb.class_log_prior_)  # log P(c) for each class\n",
        "print(\"Class priors (actual):\", np.exp(binary_nb.class_log_prior_))  # P(c)\n",
        "\n",
        "print(\"\\nVocabulary size:\", len(binary_vectorizer.vocabulary_))  # Number of unique words\n",
        "print(\"Feature names (first word):\", binary_vectorizer.get_feature_names_out()[0])  # First word\n",
        "\n",
        "print(\"\\nFeature log probabilities shape:\", binary_nb.feature_log_prob_.shape)  # (classes, features)\n",
        "# This is log P(word_present|class) for binary features\n",
        "\n",
        "# Example: probability of first word being present given each class\n",
        "for i, class_name in enumerate(binary_nb.classes_):\n",
        "    print(f\"\\n{class_name} class - first word presence probability:\")\n",
        "    word = binary_vectorizer.get_feature_names_out()[0]\n",
        "    log_prob = binary_nb.feature_log_prob_[i][0]\n",
        "    actual_prob = np.exp(log_prob)\n",
        "    print(f\"  P('{word}' present|{class_name}) = {actual_prob:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3-06MRt1lGC",
        "outputId": "d32df323-684c-41e4-9bca-4b43c05cc67e"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "binary_nb trained:\n",
            "\n",
            "Classes: ['negative' 'positive']\n",
            "\n",
            "Class log priors: [-0.51082562 -0.91629073]\n",
            "Class priors (actual): [0.6 0.4]\n",
            "\n",
            "Vocabulary size: 39\n",
            "Feature names (first word): about\n",
            "\n",
            "Feature log probabilities shape: (2, 39)\n",
            "\n",
            "negative class - first word presence probability:\n",
            "  P('about' present|negative) = 0.400000\n",
            "\n",
            "positive class - first word presence probability:\n",
            "  P('about' present|positive) = 0.250000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TRNkn08c20vp"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compare predictions from both approaches\n"
      ],
      "metadata": {
        "id": "txbux4b8222D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pPSTNJb2-hL",
        "outputId": "9af2b779-dc5c-4cff-a91e-007e53499d8f"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['positive', 'negative', 'positive']"
            ]
          },
          "metadata": {},
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Multinomial NB predictions:\", multinomial_nb.predict(X_test_counts))\n",
        "print(\"Binary NB predictions:\", binary_nb.predict(X_test_binary))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBuMnj4_2NZQ",
        "outputId": "50061eb9-7181-4e88-d62a-b5e107ce2eb2"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multinomial NB predictions: ['negative' 'positive' 'positive']\n",
            "Binary NB predictions: ['negative' 'negative' 'positive']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "phU5R-Hf23Jq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}